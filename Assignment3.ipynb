{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.matlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_batch(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        dataset = pickle.load(f, encoding='latin1') # Nxd(3072) (Nx (32x32x3))\n",
    "        X = np.transpose(dataset['data'] / 255.) # d x N\n",
    "        mean_X = np.mean(X, axis=1) # mean of each row (each feature mean)\n",
    "        std_X = np.std(X, axis=1)\n",
    "        X = X - np.matlib.repmat(mean_X, X.shape[1], 1).T\n",
    "        X = np.divide(X, np.matlib.repmat(std_X, X.shape[1], 1).T)\n",
    "        \n",
    "        y = np.array(dataset['labels'])\n",
    "        Y = np.transpose(np.eye(X.shape[1], np.max(y) + 1)[y]) # K x N\n",
    "        return X, Y, y\n",
    "\n",
    "def load_all(validation_size):\n",
    "    X_1, Y_1, y_1 = load_batch('data/data_batch_1')\n",
    "    X_2, Y_2, y_2 = load_batch('data/data_batch_2')\n",
    "    X_3, Y_3, y_3 = load_batch('data/data_batch_3')\n",
    "    X_4, Y_4, y_4 = load_batch('data/data_batch_4')\n",
    "    X_5, Y_5, y_5 = load_batch('data/data_batch_5')\n",
    "    \n",
    "    X = np.concatenate((X_1, X_2, X_3, X_4, X_5[:,:-validation_size]), axis=1)\n",
    "    Y = np.concatenate((Y_1, Y_2, Y_3, Y_4, Y_5[:,:-validation_size]), axis=1)\n",
    "    y = np.concatenate((y_1, y_2, y_3, y_4, y_5[:-validation_size]))\n",
    "    \n",
    "    X_valid = X_5[:,-validation_size:]\n",
    "    Y_valid = Y_5[:,-validation_size:]\n",
    "    y_valid = y_5[-validation_size:]\n",
    "    return X, Y, y, X_valid, Y_valid, y_valid\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_normalize(scores, mean, variance):\n",
    "    return np.dot(np.pow(np.diag(variance + 1e-9), -0.5), (s - np.array([mean]).transpose()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(s):\n",
    "    exponent = np.exp(s)\n",
    "    return np.divide(exponent, np.sum(exponent, axis=0))\n",
    "\n",
    "def evaluate_classifier(X, layers):\n",
    "    num_layers = len(layers)\n",
    "    H = []\n",
    "    S = []\n",
    "    S_norm = []\n",
    "    \n",
    "    layer_means = []\n",
    "    layer_variances = []\n",
    "    \n",
    "    h_prev = X\n",
    "    \n",
    "    for i, layer in enumerate(layers):\n",
    "        if i == num_layers - 1:  # If last layer\n",
    "            P = softmax(np.dot(layer[\"W\"], h_prev) + layer[\"b\"]) # K x N\n",
    "            return H, P, S, S_norm, layer_means, layer_variances\n",
    "        else:\n",
    "            s = np.dot(layer[\"W\"], h_prev) + layer[\"b\"] # m x N\n",
    "            S.append(s)\n",
    "            \n",
    "            mean = np.mean(s, axis=1) # m len\n",
    "            variance = np.mean(np.square(s - np.array([mean]).transpose()), axis=1) # m\n",
    "            \n",
    "            layer_means.append(mean)\n",
    "            layer_variances.append(variance)\n",
    "            \n",
    "            gamma = 1\n",
    "            beta = 0\n",
    "            \n",
    "            normalized = batch_normalize(scores, mean, variance)\n",
    "            S_norm.append(normalized)\n",
    "            \n",
    "            transformed = np.multiply(gamma, normalized) + beta\n",
    "            \n",
    "            h = np.maximum(s, 0) # ReLU; m x N\n",
    "            H.append(h)\n",
    "            h_prev = h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 1]\n",
      " [2 9]]\n",
      "[1.5 2.  5.5]\n",
      "[[-0.5  0.5]\n",
      " [ 1.  -1. ]\n",
      " [-3.5  3.5]]\n"
     ]
    }
   ],
   "source": [
    "def compute_cost(X, Y, layers, lmb):\n",
    "    H, P = evaluate_classifier(X, layers)[:2]\n",
    "    n = np.sum(np.multiply(Y, P), axis=0)\n",
    "    cross_entropy = np.sum(-np.log(n))\n",
    "    \n",
    "    w_square_sum = 0\n",
    "    if lmb > 0:\n",
    "        for layer in layers:\n",
    "            w_square_sum += np.sum(np.diag(np.dot(layer[\"W\"].T, layer[\"W\"])))\n",
    "    return (cross_entropy / X.shape[1]) + (lmb * w_square_sum)\n",
    "\n",
    "def compute_gradients(X, Y, layers, lmb):\n",
    "    H, P, S, S_norm, layer_means, layer_variances = evaluate_classifier(X, layers)\n",
    "    G = -(Y - P)\n",
    "    Nb = X.shape[1] # batch size\n",
    "    \n",
    "    W_gradients = []\n",
    "    b_gradients = []\n",
    "    for i, layer in reversed(list(enumerate(layers))): # from last to first\n",
    "        if i > 0:\n",
    "            grad_W = np.divide(np.dot(G, H[i - 1].T), Nb) + (2 * lmb * layer[\"W\"]) # J w.r.t W_k\n",
    "            grad_b = np.divide(np.dot(G, np.ones((Nb, 1))), Nb) # J w.r.t b_k\n",
    "            \n",
    "            G = np.dot(layer[\"W\"].T, G)\n",
    "            G = G * (H[i - 1] > 0).astype(int) # element-wise\n",
    "            \n",
    "            gamma_grad = np.dot(np.divide(np.multiply(G, S_norm), Nb), np.ones((Nb, 1)))\n",
    "            beta_grad = np.divide(np.dot(G, np.ones((Nb, 1))))\n",
    "            \n",
    "            G = np.multiply(G, np.dot()\n",
    "            \n",
    "            W_gradients.append(grad_W)\n",
    "            b_gradients.append(grad_b)\n",
    "        else: # first layer\n",
    "            grad_W = np.divide(np.dot(G, X.T), Nb) + (2 * lmb * layer[\"W\"])\n",
    "            grad_b = np.divide(np.dot(G, np.ones((Nb, 1))), Nb)\n",
    "            W_gradients.append(grad_W)\n",
    "            b_gradients.append(grad_b)\n",
    "    return W_gradients, b_gradients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
